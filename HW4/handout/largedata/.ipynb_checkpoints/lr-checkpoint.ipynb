{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dict(filename):\n",
    "\n",
    "\tword_dict = dict()\n",
    "\twith open(filename,'r') as f:\n",
    "\t\tfor line in f.readlines():\n",
    "\t\t\t[word,num] = line.split()\n",
    "\t\t\tword_dict[word] = int(num)\n",
    "\treturn word_dict\n",
    "\n",
    "\n",
    "def read_formatted_tsv(filename, dim):\n",
    "\twith open( filename, 'r') as f:\n",
    "\t\treader = csv.reader(f, delimiter = '\\t')\n",
    "\t\tcontent = list(reader)\n",
    "\n",
    "\tnum_feature = len(content)\n",
    "\tlabel = []\n",
    "\tfeature = []\n",
    "\n",
    "\tfor line in content:\n",
    "\t\tlabel.append( int(line[0]) )\n",
    "\t\tcomment = line[1:]\n",
    "\t\tfeature_dict = dict()\n",
    "\t\tfor ele in comment:\n",
    "\t\t\t[key,val] = ele.split(':')\n",
    "\t\t\tfeature_dict[ int(key) ] = int(val)\n",
    "\t\tfeature_dict[dim] = 1     # bias term in the end\n",
    "\t\tfeature.append(feature_dict)\n",
    "\n",
    "\treturn num_feature, feature, label\n",
    "\n",
    "def sparse_dot(X,W):\n",
    "\tproduct = 0.0\n",
    "\tfor key in X.keys():\n",
    "\t\tproduct += X[key]*W[key]\n",
    "\treturn product\n",
    "\n",
    "def cal_loss_i(theta,x,y):\n",
    "\tloss_i = -float(y)*sparse_dot(x,theta) + math.log( 1 + math.exp( sparse_dot(x,theta) ) )\n",
    "\treturn loss_i\n",
    "\n",
    "def cal_loss(feature,label,W):\n",
    "\tnum_data = len(feature)\n",
    "\tloss = 0.0\n",
    "\n",
    "\tfor i in range(num_data):\n",
    "\t\tloss += cal_loss_i( W,feature[i],label[i] )\n",
    "\treturn loss\n",
    "\n",
    "def cal_gradient(theta,x,y):\n",
    "\tgradient = {}\n",
    "\texp_term = math.exp( sparse_dot(x,theta) )\n",
    "\n",
    "\tfor key in x.keys():\n",
    "\t\tgradient[key] = -x[key]*( y - exp_term/(1 + exp_term) )\n",
    "\treturn gradient\n",
    "\n",
    "def update(W,gradient,learning_rate):\n",
    "\n",
    "\tfor key in gradient.keys():\n",
    "\t\tW[key] -= learning_rate*gradient[key]\n",
    "\treturn W\n",
    "\n",
    "def train(feature, label, W, feature_valid, label_valid, num_epoch, learning_rate):\n",
    "\n",
    "\tnum_data = len(feature)\n",
    "\tloss_train = []\n",
    "\tloss_train.append( cal_loss(feature,label,W) )\n",
    "    loss_valid = []\n",
    "    loss_valid.append( cal_loss(feature_valid,label_valid,W) )\n",
    "\tfor _ in range(num_epoch):\n",
    "\n",
    "\t\tfor x,y in zip( feature, label):\n",
    "\t\t\tgradient = cal_gradient(W,x,y)\n",
    "\t\t\tW = update(W,gradient,learning_rate)\n",
    "\n",
    "\t\tloss_train.append( cal_loss(feature,label,W) )\n",
    "        loss_valid.append( cal_loss(feature_valid,label_valid,W) )\n",
    "\treturn W, loss_train, loss_valid\n",
    "\n",
    "def predict(feature,label,W):\n",
    "\n",
    "\tnum_data = len(feature)\n",
    "\tpred_label = []\n",
    "\terror_num = 0\n",
    "\n",
    "\tfor i in range(num_data):\n",
    "\t\tx, y = feature[i], label[i]\n",
    "\n",
    "\t\tpred_val = math.exp( sparse_dot(x,W) )/( 1 + math.exp( sparse_dot(x,W) ))\n",
    "\n",
    "\t\tif pred_val >= 0.5:\n",
    "\t\t\tpred_y = 1\n",
    "\t\telse:\n",
    "\t\t\tpred_y = 0\n",
    "\n",
    "\t\tpred_label.append(pred_y)\n",
    "\n",
    "\t\tif pred_y != y:\n",
    "\t\t\terror_num += 1\n",
    "\n",
    "\terror = error_num/num_data\n",
    "\n",
    "\treturn error, pred_label\n",
    "\n",
    "def write_output( train_label_file, test_label_file,metricsfile,train_label, test_label,error_train, error_test):\n",
    "\twith open(metricsfile,'w') as f:\n",
    "\t\tf.write('error(train): ' + str(error_train) + '\\n')\n",
    "\t\tf.write('error(test): ' + str(error_test) )\n",
    "\n",
    "\twith open(train_label_file,'w') as f:\n",
    "\t\tfor label in train_label:\n",
    "\t\t\tf.write( str(label) + '\\n')\n",
    "\n",
    "\twith open(test_label_file,'w') as f:\n",
    "\t\tfor label in test_label:\n",
    "\t\t\tf.write( str(label) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = 'formatted_train.tsv'\n",
    "validation_input = 'formatted_valid.tsv'\n",
    "test_input = 'formatted_test.tsv'\n",
    "dict_input = 'dict.txt'\n",
    "train_out = 'train_out.labels'\n",
    "test_out = 'test_out.labels'\n",
    "metrics_out = 'metrics_out.txt'\n",
    "num_epoch = 200\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "word_dict = read_dict(dict_input)\n",
    "dim = len(word_dict)\n",
    "\n",
    "num_feature_train, feature_train, label_train = read_formatted_tsv(train_input, dim)\n",
    "num_feature_valid, feature_valid, label_valid = read_formatted_tsv(validation_input, dim)\n",
    "num_feature_test,  feature_test,  label_test  = read_formatted_tsv(test_input, dim)\n",
    "\n",
    "# Initialize W\n",
    "W = [0]*dim + [0]      # dim + 1 for the bias term\n",
    "\n",
    "W, loss = train(feature_train, label_train,feature_valid,label_valid, W, num_epoch, learning_rate)\n",
    "\n",
    "# prediction\n",
    "error_train, train_label = predict(feature_train, label_train, W)\n",
    "error_test,  test_label  = predict(feature_test,  label_test,  W)\n",
    "write_output( train_out, test_out,metrics_out,train_label, test_label,error_train, error_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
